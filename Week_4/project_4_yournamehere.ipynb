{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- besure to put the title, name, email and date here in a markdown cell! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import clear_output\n",
    "display(HTML(\"<style>.container { width:90% }</style>\"))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# -- sklearn modules \n",
    "from sklearn.model_selection import train_test_split   #- partition train/test split \n",
    "from sklearn.tree import DecisionTreeClassifier        #- create a decison tree \n",
    "from sklearn.ensemble import ExtraTreesClassifier      #- random trees \n",
    "from sklearn.ensemble import RandomForestClassifier    #- random forest classifier \n",
    "\n",
    "# -- we need this to make our pipeline \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# -- categorical encoders -- \n",
    "from category_encoders import *\n",
    "\n",
    "\n",
    "# -- need this to render charts in notebook -- \n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 4,  Who is Likely to Default?\n",
    "\n",
    "The bosses were excited about your promotion model, but now they have a whole lot of new loans comming through. Can you identify which of these new loans are likely to default? Youâ€™ll build a model that can be used to hedge the institution's default risk. To do this you will predict which loans will end up in default status (0 â€“ Paid in Full) or (1 â€“ Default) status. In this project you will draw on your Python ML skills to analyze loan default risk. You are given two datasets one training dataset and one prediction dataset. \n",
    "\n",
    "The following Tasks have been dived into Three(3) parts, simply look at the section's **Todos** for your project's required tasks. If there is a question, simply add a markdown cell and answer the question. As always feel free to add additional cells and analysis as you dig into the data.  \n",
    "\n",
    "\n",
    "### Part 1\n",
    "1. Stage data\n",
    "2. Clean up column names \n",
    "3. Describe data \n",
    "4. Transform & create new columns \n",
    "5. Explore likely predictors  \n",
    "\n",
    "### Part 2.\n",
    "\n",
    "6. Partition into 75/25 split \n",
    "\n",
    "7. Train ExtraTrees, RandomForest and GradientBoosting Classifier\n",
    "    - onehot encoding \n",
    "    - target encoding  \n",
    "    - Tune Parameters \n",
    "    - feature importance \n",
    "    \n",
    "8. Evaluate & Compare Performance of Each \n",
    "    - confusion matrix \n",
    "    - calculate accuracy \n",
    "    - Receiver Operator Characteristic (ROC Chart) \n",
    "    - Area Under the Curve (AUC)\n",
    "    - Recal(TPR) @4% FPR  \n",
    "\n",
    "\n",
    "### Part 3.  \n",
    "\n",
    "10. Write up your thoughts.\n",
    "    - which model perfomed the best? \n",
    "    - Did the models have similar feature importance? \n",
    "    - For your best performing RandomForest and GBM models at a false positive rate of 4% what is the true positive rate? and score thresholds. What would be the business rule you would tell the business to implement? \n",
    "    - Given the loan amount, how much would your model save in identified defaults? how did you calculate this? \n",
    "    \n",
    "11. Make a new prediction file, submit to kaggle \n",
    "    - apply your best model to the predict dataset and submit your prediction to kaggle. \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. \n",
    "## 1. Stage \n",
    "----- \n",
    "Import both loans.csv to df,  and the predict.csv to predict \n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    " \n",
    "1. Read loan.csv into a dataframe named df \n",
    "2. Read predict.csv into a dataframe named predict \n",
    "3. use df.head() to display the first 5 records of each \n",
    "\n",
    "</div>\n",
    "\n",
    "```python \n",
    "df = pd.read_csv(\"../Week_3/Data/bank-additional-full.csv\", header=0, sep=';', quotechar='\"')\n",
    "df.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current_Loan_Amount</th>\n",
       "      <th>Term</th>\n",
       "      <th>Credit_Score</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Years_in_current_job</th>\n",
       "      <th>Home_Ownership</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Monthly_Debt</th>\n",
       "      <th>Years_of_Credit_History</th>\n",
       "      <th>Months_since_last_delinquent</th>\n",
       "      <th>Number_of_Open_Accounts</th>\n",
       "      <th>Number_of_Credit_Problems</th>\n",
       "      <th>Current_Credit_Balance</th>\n",
       "      <th>Maximum_Open_Credit</th>\n",
       "      <th>Bankruptcies</th>\n",
       "      <th>Tax_Liens</th>\n",
       "      <th>ID</th>\n",
       "      <th>loan_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>262328.0</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>Home Mortgage</td>\n",
       "      <td>Debt Consolidation</td>\n",
       "      <td>33295.98</td>\n",
       "      <td>21.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229976.0</td>\n",
       "      <td>850784.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>215952.0</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>739.0</td>\n",
       "      <td>1454735.0</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Debt Consolidation</td>\n",
       "      <td>39277.75</td>\n",
       "      <td>13.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>669560.0</td>\n",
       "      <td>1021460.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>728.0</td>\n",
       "      <td>714628.0</td>\n",
       "      <td>3 years</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Debt Consolidation</td>\n",
       "      <td>11851.06</td>\n",
       "      <td>16.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>203965.0</td>\n",
       "      <td>289784.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>740.0</td>\n",
       "      <td>776188.0</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>Debt Consolidation</td>\n",
       "      <td>11578.22</td>\n",
       "      <td>8.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134083.0</td>\n",
       "      <td>220220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>743.0</td>\n",
       "      <td>1560907.0</td>\n",
       "      <td>4 years</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Debt Consolidation</td>\n",
       "      <td>17560.37</td>\n",
       "      <td>13.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225549.0</td>\n",
       "      <td>496474.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Current_Loan_Amount        Term  Credit_Score  Annual_Income  \\\n",
       "0             262328.0  Short Term           NaN            NaN   \n",
       "1             215952.0  Short Term         739.0      1454735.0   \n",
       "2           99999999.0  Short Term         728.0       714628.0   \n",
       "3           99999999.0  Short Term         740.0       776188.0   \n",
       "4           99999999.0  Short Term         743.0      1560907.0   \n",
       "\n",
       "  Years_in_current_job Home_Ownership             Purpose  Monthly_Debt  \\\n",
       "0            10+ years  Home Mortgage  Debt Consolidation      33295.98   \n",
       "1             < 1 year           Rent  Debt Consolidation      39277.75   \n",
       "2              3 years           Rent  Debt Consolidation      11851.06   \n",
       "3             < 1 year       Own Home  Debt Consolidation      11578.22   \n",
       "4              4 years           Rent  Debt Consolidation      17560.37   \n",
       "\n",
       "   Years_of_Credit_History  Months_since_last_delinquent  \\\n",
       "0                     21.1                           8.0   \n",
       "1                     13.9                           NaN   \n",
       "2                     16.0                          76.0   \n",
       "3                      8.5                          25.0   \n",
       "4                     13.3                           NaN   \n",
       "\n",
       "   Number_of_Open_Accounts  Number_of_Credit_Problems  Current_Credit_Balance  \\\n",
       "0                     35.0                        0.0                229976.0   \n",
       "1                     20.0                        0.0                669560.0   \n",
       "2                     16.0                        0.0                203965.0   \n",
       "3                      6.0                        0.0                134083.0   \n",
       "4                     10.0                        1.0                225549.0   \n",
       "\n",
       "   Maximum_Open_Credit  Bankruptcies  Tax_Liens   ID  loan_default  \n",
       "0             850784.0           0.0        0.0   20             0  \n",
       "1            1021460.0           0.0        0.0  100             0  \n",
       "2             289784.0           0.0        0.0  110             0  \n",
       "3             220220.0           0.0        0.0  130             0  \n",
       "4             496474.0           1.0        0.0  140             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/loans.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "751.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Credit_Score'] = np.where((df[\"Credit_Score\"] > 1000),df['Credit_Score']/10,df['Credit_Score'])\n",
    "df['Credit_Score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0    21710\n",
       "8.0      3242\n",
       "9.0      2750\n",
       "Name: current_job_years, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"current_job_years\"] = df[\"Years_in_current_job\"].map({'10+ years': 10,\n",
    "                                                          '9 years': 9,\n",
    "                                                          '8 years': 8 })\n",
    "df[\"current_job_years\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10          21710\n",
       "2 years      6451\n",
       "< 1 year     5742\n",
       "3 years      5688\n",
       "5 years      4802\n",
       "1 year       4564\n",
       "4 years      4308\n",
       "6 years      3974\n",
       "7 years      3942\n",
       "8 years      3242\n",
       "9 years      2750\n",
       "Name: current_job_years, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"current_job_years\"]  = np.where(df[\"Years_in_current_job\"] == \"10+ years\", 10, df[\"Years_in_current_job\"] )\n",
    "#df[\"current_job_years\"]  = np.where(df[\"Years_in_current_job\"] == \"10+ years\", 10, 0 )\n",
    "df[\"current_job_years\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Clean up Column Names\n",
    "\n",
    "*It's just not fun dealing with ill-formed columns*\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    " \n",
    "- remove leading and trailing characters\n",
    "- replace spaces with underscores _ \n",
    "- replace \".\" with underscores _ \n",
    "- change case to lower case\n",
    "- remove various special characters\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Describe data\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    " \n",
    "- check target, counts and PCTs \n",
    "- generate descriptive statisicts with describe \n",
    "- check for nulls \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transform & Clean Variables \n",
    "\n",
    "- creditscore  \n",
    "\n",
    "- current loan amount\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    "    \n",
    "<b> transform years_in_current_job </b>\n",
    "\n",
    "\n",
    "- create a new variable current_job_years by doing the following\n",
    "\n",
    "    - if 10+ years then current_job_years = 10\n",
    "    - if 1-9 years then parse into appropriate years \n",
    "    - if < 1 year then 0 \n",
    "    - be sure do do a value_counts() on the new variable, afterwards to show that you've transformed it corectly. \n",
    " \n",
    "<b> fix creditscore </b> \n",
    "\n",
    "- if creditscore > 1000 then divide by 10 \n",
    "\n",
    "<b> fix current_loan_amount </b>\n",
    "\n",
    "- if current_loan_amount == 99999999, then set current_loan_amt to -1 \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explore likely predictors \n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    " \n",
    "- Pick 3 character columns \n",
    "    - crosstab \n",
    "    - frequency count by target  \n",
    "    - percentage by target \n",
    "\n",
    "- Pick new  variable \"current_job_years\" treat it as a character and perform the following   \n",
    "    - crosstab \n",
    "    - frequency count by target  \n",
    "    - percentage by target \n",
    "\n",
    "- Pick credit_score numeric columns \n",
    "    - cut them into bins \n",
    "    - frequency count by target \n",
    "    - percentage by target \n",
    "    \n",
    "- Pick annual_income numeric column \n",
    "    - cut them into bins \n",
    "    - frequency count by target \n",
    "    - percentage by target \n",
    "    \n",
    "- Pick two other numeric columns and explore them \n",
    "    - cut them into bins \n",
    "    - frequency count by target \n",
    "    - percentage by target \n",
    "    \n",
    "    \n",
    "- And you of course can do any other exploration you think will be useful. \n",
    "\n",
    "- use seaborn's pairs plot like we've seen a couple times already. \n",
    "\n",
    "**Answer**\n",
    "1. does anything stand out to you about these plots? \n",
    "2. do you think any of these will be good predictors of our target? \n",
    "3. can you think of anther graphic which might be useful to identify default vs. non-default. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2.\n",
    "## 6. Partition into 75/25 split \n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    "    \n",
    "- partition into 75/25 split.. \n",
    "- print out the percentages \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train an ExtraTreesClassifier, a RandomForestClassifier and a GBM \n",
    "\n",
    "-----\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    "    \n",
    "- Deterimine which columns go into \n",
    "    - target\n",
    "    - numeric features\n",
    "    - categorical features \n",
    "    \n",
    "- Create ExtraTree pipeline\n",
    "    - categorical handling - up to you to choose how you'd want to handle \n",
    "        - missing value handling, categorical encoding \n",
    "        - use a loop or gridsearch to evaluate hyperparameters: \n",
    "            - n_estimators = 100, 150, 200 \n",
    "            - max_depth = 5, 10, 20\n",
    "        - evaluate on TEST set, select the ExtraTree model hyperparameters with best AUC \n",
    "        - print Train/Test AUC & Accuracy\n",
    "        - plot Variable Importance \n",
    "        \n",
    "- Create RandomForest pipeline\n",
    "    - categorical handling - up to you to choose how you'd want to handle \n",
    "        - missing value handling, categorical encoding \n",
    "        - use a loop or gridsearch  to evaluate hyperparameters: \n",
    "            - n_estimators = 100, 150, 200 \n",
    "            - max_depth = 5, 10, 20\n",
    "        - evaluate on TEST set, select the RandomForest model hyperparameters with best AUC \n",
    "        - print best hyperparameter combination \n",
    "        - print Train/Test AUC & Accuracy\n",
    "        - plot Variable Importance \n",
    "         \n",
    "        \n",
    "        \n",
    "- Create GradientBoostingMaching(GBM) pipeline\n",
    "    - categorical handling - up to you to choose how you'd want to handle \n",
    "        - missing value handling, categorical encoding \n",
    "        - use a loop or gridsearch to evaluate hyperparameters: \n",
    "            - learning_rate = 0.01, 0.05, 0.1, 0.5, 1\n",
    "            - n_estimators = 100, 200 \n",
    "        - evaluate on TEST set, select the GradientBoostingMaching model hyperparameters with best AUC \n",
    "        - print best hyperparameter combination \n",
    "        - print Train/Test AUC & Accuracy\n",
    "        - plot Variable Importance \n",
    "\n",
    "> hint make your life easier and make functions! \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate \n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    "    \n",
    "FOR EACH OF YOUR BEST classifiers calculate the following \n",
    "1. calculate the varaible importance\n",
    "2. confusion matrix of test counts \n",
    "3. confusion matrix of test percentages \n",
    "4. accuracy of both train and test vs baseline (i.e. the do nothing case) \n",
    "5. create a ROC chart with AUC calcualtion comparing training and testing \n",
    "6. make a table of FPR, TPR and Threshold from 0 - 10% FPR \n",
    "\n",
    "\n",
    "> hint make your life easier and make functions! \n",
    "</div>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Write up.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    "\n",
    "- which model perfomed the best? What was the best hyperparamert combination?  \n",
    "- Did the models have similar feature importance? did different categorical encodings make a difference? and which do you think is more likely to lead to overfitting and why? \n",
    "- for your best performing ExtraTree, RandomForest and GBM models at a false positive rate of 4% what is the true positive rate? and score thresholds. What would be the business rule you would tell the business to implement? \n",
    "\n",
    "- If you apply gthe business rule at 4% FPR on your best model,  how many True Positives would your model find on the Test Set vs False Positives, if you made \\\\$1000 and -\\\\$200 for each false positive how much would your model make? \n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
