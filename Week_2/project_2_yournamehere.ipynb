{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- besure to put the title, name, email and date here in a markdown cell! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Load Packages\n",
    "-------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import clear_output\n",
    "display(HTML(\"<style>.container { width:90% }</style>\"))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# -- sklearn modules \n",
    "from sklearn.model_selection import train_test_split   #- partition train/test split \n",
    "from sklearn.tree import DecisionTreeClassifier        #- create a decison tree \n",
    "from sklearn.tree import export_text                   #- export tree as text rules \n",
    "from sklearn import tree\n",
    "\n",
    "# -- visualize decision trees and decision surfaces \n",
    "import graphviz \n",
    "\n",
    "# -- need this to render charts in notebook -- \n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks \n",
    "### Part 1\n",
    "1. Stage data\n",
    "2. Clean up column names \n",
    "3. Describe data \n",
    "4. Explore likely predictors  \n",
    "\n",
    "### Part 2.\n",
    "5. Partition into 75/25 split \n",
    "6. Train a decision tree model 1\n",
    "7. Train a 2nd decision tree model 2 \n",
    "8. Train a 3rd decision tree model 3\n",
    "9. Evaluate Performance of models 1, 2 and 3\n",
    "\n",
    "### Part 3.  \n",
    "10. Write up your thoughts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. \n",
    "## 1. Stage \n",
    "----- \n",
    "Import your curn.csv dataset into a pandas dataframe\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    " \n",
    "1. Read churn.csv into a dataframe named df \n",
    "2. use df.head() to display the first 5 records \n",
    "</div>\n",
    "\n",
    "```python\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Clean up Column Names\n",
    "\n",
    "*It's just not fun dealing with ill-formed columns*\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    " \n",
    "1. clean names \n",
    "    - remove leading and trailing characters\n",
    "    - replace spaces with underscores _ \n",
    "    - change case to lower case\n",
    "    - remove various special characters\n",
    "2. print column names \n",
    "3. use head to display first 5 records \n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "**Todo:**\n",
    "\n",
    "\n",
    "This is how I clean up column names. \n",
    "\n",
    "```python\n",
    "df.columns = ( df.columns\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(' ', '_')\n",
    "    .str.replace('-', '_')\n",
    "    .str.replace('(', '')\n",
    "    .str.replace(')', '')\n",
    "    .str.replace('?', '')\n",
    "    .str.replace('\\'', '') # notice the backslash \\ this is an escape character\n",
    ")\n",
    "print(df.columns)\n",
    "df.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Describe data\n",
    "### Check Target Distribution \n",
    "\n",
    "-----\n",
    "Always start by understanding your **\"target\"** column this will determine how you are going to perform your analysis \n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    " \n",
    "1. use value_counts on churn column to display count \n",
    "2. use value_counts but normalize the results so you get percentages \n",
    "3. use columns to display column names \n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe \n",
    "---------\n",
    "Always take a look at your data to see what you are dealing with. I recomend using describe and dtypes to understand what i've just imported. \n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    "\n",
    "1. use describe to print out descriptive statitiscs, what does T do and what does sort_values do? \n",
    "2. use dtypes to output data types, what is an object data type. are their numbers that should be considered categorical? think area codes\n",
    "</div>\n",
    "\n",
    "\n",
    "```python\n",
    "df.describe(include='all').T.sort_values('unique')\n",
    "df.dtypes\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out Nulls \n",
    "----\n",
    "Null values can be interesting but you have to deal with them when we get to building models. \n",
    "\n",
    "**Step 1. is to identify your problem areas.**  \n",
    "\n",
    "Step 2. figure out if there is any predictive power in the nulls - not necesary here! \n",
    "\n",
    "Step 3. handle them. - not necessary yet! \n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    " \n",
    "1. Identify if any columns contain nulls. \n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore likely predictors\n",
    "### Make Histograms, Crosstabs and Barcharts \n",
    "\n",
    "\n",
    "Todo: \n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    " \n",
    "1. Histogram 1 - Pick a *NUMERIC* column that you think might be useful and make a histogram. \n",
    "    - 1a. make sure you have one color for churn == True and another for churn == False. \n",
    "    - 1b. in a markdown cell explain why you think this might be a good predictor of churn. \n",
    "    \n",
    "2. Histogram 2 - Pick a *Second NUMERIC* column that you think might be useful \n",
    "    - 1a. make sure you have one color for churn == True and another for churn == False. \n",
    "    - 1b. in a markdown cell explain why you think this might be a good predictor of churn. \n",
    "    \n",
    "3. Barchart 1 - Pick a *CHARACTER* column that you think might be useful \n",
    "    - 1a. make sure you have counts and that you can overlay them. \n",
    "    - 1b. make sure you use normalize=\"index\" to get percentages and that you can overlay them, and use bottom= \n",
    "    - 1c. in a markdown cell explain why you think this might be a good predictor of churn. \n",
    "    \n",
    "4. Barchart 2 - Pick a *Second CHARACTER* column that you think might be useful \n",
    "    - 1a. make sure you have counts and that you can overlay them. \n",
    "    - 1b. make sure you use normalize=\"index\" to get percentages and that you can overlay them, and use bottom= \n",
    "    - 1c. in a markdown cell explain why you think this might be a good predictor of churn. \n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.\n",
    "### 5. Partition into 75/25 split\n",
    "-----\n",
    "Sklearn is our main pakage, we imported **train_test_split** from the model selection module. Why do we need to split the data? well we do it so that we are making predictions on an out-of-sample data, meaning will our prediction generalize to new and unseen data? it isn't fair to evaluate our prediction if it's seen the data before right? i mean you wouldn't go to your psychic and tell them exactly what you want to hear before they do your the reading?\n",
    "\n",
    "So what percentage to use? the general rule of thumb is a 70/30 or 75/25 training test split. you'll \"train\" your model on 70% of the data and evaluate it on 30%. \n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    "    \n",
    "1. convert churn False. to 0 and True. to 1 so we have numeric targets \n",
    "2. partition your data into a 70/30 split, using train_test_split  \n",
    "3. print the percentages \n",
    "    \n",
    " </div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train 1st decision tree model pipeline \n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    "\n",
    "1. specify your feature list \n",
    "    - target variable: this is simply your \n",
    "    - numeric_features: these are the numeric variables you think are likely useful in predicting churn. \n",
    "    - categorical_features: these are the categorical variables you belive are likely useful in predicting churn. \n",
    "    \n",
    "2. define your categorical pipeline it should \n",
    "    - 2a. deal with missing values hint: SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    - 2b. convert categories to one hot encoded data, hint: OneHotEncoder(handle_unknown='ignore'))\n",
    "    \n",
    "3. define your numeric pipeline it should \n",
    "    - 3a. replace missing values with a -1 hint:  ('imputer', SimpleImputer(strategy='constant', fill_value=-1)),\n",
    "   \n",
    "4. pull categorical pipeline and numeric pipeline into a preprocessor using ColumnTransformer()\n",
    "    - 4a. specify your categorical and numeric features to be transformed \n",
    "    \n",
    "5. create decision_tree1 pipeline by bringing your preprocessor and specifiy your decision tree classifier with the following hyperparameters:\n",
    "    - max_depth = 10,\n",
    "    - min_samples_leaf = 10, \n",
    "    - criterion = 'gini'\n",
    "\n",
    "6. fit decision_tree1.fit(X_train, y_train) \n",
    "\n",
    "\n",
    " </div>\n",
    "\n",
    "Here is a simple pipeline recipe for a decision tree \n",
    "\n",
    "```python\n",
    "\n",
    "# -- this is your pipeline based model -- \n",
    "categorical_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "numerical_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "preprocessing = ColumnTransformer(transformers=[\n",
    "    ('cat', categorical_pipe, categorical_features),\n",
    "    ('num', numerical_pipe, numeric_features)\n",
    "    ])\n",
    "\n",
    "decision_tree = Pipeline([\n",
    "    ('preprocess', preprocessing),\n",
    "    ('classifier', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "decision_tree = decision_tree.fit(train[categorical_features + numeric_features], train[target])\n",
    "decision_tree\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train 2nd decision tree model pipeline \n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    "\n",
    "1. specify your feature list\n",
    "    - target variable: this is simply your \n",
    "    - numeric_features:\n",
    "    \n",
    "        - <b>this time remove \"day_min\" from numeric varaibles</b>\n",
    "    - categorical_features: \n",
    "    \n",
    "        - <b>this time remove \"vmail_plan\" from your categorical varaibles</b>\n",
    "    \n",
    "2. define your categorical pipeline it should \n",
    "    - 2a. deal with missing values hint: SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    - 2b. convert categories to one hot encoded data, hint: OneHotEncoder(handle_unknown='ignore'))\n",
    "    \n",
    "3. define your numeric pipeline it should \n",
    "    - 3a. replace missing values with a -1 hint:  ('imputer', SimpleImputer(strategy='constant', fill_value=-1)),\n",
    "   \n",
    "4. pull categorical pipeline and numeric pipeline into a preprocessor using ColumnTransformer()\n",
    "    - 4a. specify your categorical and numeric features to be transformed \n",
    "    \n",
    "5. create decision_tree2 pipeline by bringing your preprocessor and specifiy your decision tree classifier with the following hyperparameters:\n",
    "    - max_depth = 10,\n",
    "    - min_samples_leaf = 10, \n",
    "    - criterion = 'entropy'\n",
    "\n",
    "6. fit decision_tree2.fit(X_train, y_train) \n",
    "\n",
    "\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train 3rd decision tree model pipeline \n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    "\n",
    "1. specify your feature list\n",
    "    - target variable: this is simply your \n",
    "    - numeric_features:\n",
    "        - <b>this time remove drop \"eve_charge\" from your numeric varaibles</b>\n",
    "    - categorical_features: \n",
    "    \n",
    "        - <b>this time remove drop \"intl_plan\" from your categorical varaibles</b>\n",
    "    \n",
    "2. define your categorical pipeline it should \n",
    "    - 2a. deal with missing values hint: SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    - 2b. convert categories to one hot encoded data, hint: OneHotEncoder(handle_unknown='ignore'))\n",
    "    \n",
    "3. define your numeric pipeline it should \n",
    "    - 3a. replace missing values with a -1 hint:  ('imputer', SimpleImputer(strategy='constant', fill_value=-1)),\n",
    "   \n",
    "4. pull categorical pipeline and numeric pipeline into a preprocessor using ColumnTransformer()\n",
    "    - 4a. specify your categorical and numeric features to be transformed \n",
    "    \n",
    "5. create decision_tree3 pipeline by bringing your preprocessor and specifiy your decision tree classifier with the following hyperparameters:\n",
    "    - max_depth = 20,\n",
    "    - min_samples_leaf = 10, \n",
    "    - criterion = 'gini'\n",
    "\n",
    "6. fit decision_tree3.fit(X_train, y_train) \n",
    "\n",
    "\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  9.  Evaluate Performance \n",
    "-----\n",
    "\n",
    "Here we want to compare the **accuracy** of our decision tree pipelines on our training data and test data and compare the **confusion matrix** on our test data.  \n",
    "\n",
    "Sklearn provides two convient function to apply our models \n",
    "\n",
    "    .predict() - predicts the \"label\" or \"target\" on a new data set. This method accepts one argument, the new data set (e.g. model. predict(X_new) ), and returns the learned label for row. \n",
    "    \n",
    "    .predict_proba() -  gives us the probabilities for the target (0 and 1) in array form. The number of probabilities for each row is equal to the number of categories in target variable. \n",
    "    \n",
    "-----\n",
    "1. Apply to training data \n",
    "2. Apply to testing data\n",
    "3. Compare accuracy and confusion matrix \n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    "\n",
    "For each model you are simply going to compare the accuracy of train vs. test and the confusion matrix on the test set. \n",
    "\n",
    "default accuracy\n",
    "1. what is the default accuracy? i.e. do nothing \n",
    "\n",
    "decision_tree1\n",
    "1. print accuracy of model on train \n",
    "2. print accurayc of model on test \n",
    "3. create a confusion matrix \n",
    "\n",
    "decision_tree2\n",
    "1. print accuracy of model on train \n",
    "2. print accurayc of model on test \n",
    "3. create a confusion matrix \n",
    "\n",
    "decision_tree3\n",
    "1. print accuracy of model on train \n",
    "2. print accurayc of model on test \n",
    "3. create a confusion matrix \n",
    "\n",
    "Answer in a markdown below:\n",
    "1. Was your model better than the default do nothing case?\n",
    "2. which model performed the best? what tells you it perfomed better?\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train['churn_pred'] = decision_tree.predict(train[numeric_features + categorical_features])\n",
    "test['churn_pred'] = decision_tree.predict(test[numeric_features + categorical_features])\n",
    "\n",
    "### Default Accuracy, i.e. do nothing predict everyone as False. \n",
    "accuracy_default = train['churn'].value_counts(normalize='True')[0]\n",
    "\n",
    "accuracy_train = accuracy_score(train['churn'], train['churn_pred'])\n",
    "accuracy_test = accuracy_score(test['churn'], test['churn_pred'])\n",
    "\n",
    "print(\"Default Accuracy : {:2.2%}\".format(accuracy_default))\n",
    "print(\"Train Accuracy   : {:2.2%}\".format(accuracy_train))\n",
    "print(\"Test Accuracy    : {:2.2%}\".format(accuracy_test))\n",
    "\n",
    "print(\"Test confusion Matrix\")\n",
    "confusion_matrix = pd.crosstab(test['churn'], test['churn_pred'],  rownames=['Actual'], colnames=['Predicted'])\n",
    "confusion_matrix_pct = pd.crosstab(test['churn'], test['churn_pred'], normalize=\"index\", rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='g')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.heatmap(confusion_matrix_pct, annot=True, fmt='g')\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Write up your thoughts.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> TODO </strong>\n",
    "\n",
    "- write-up your thoughts in a markdown cell below. Be sure to compare your model performance from this week versus last week's business rule based model(project_1). Did the models outperform your business rule? what tells you that they did or didn't? Of your different models what stood out? did changing the inputs have much impact on performance? \n",
    "\n",
    "\n",
    "- finally besure to run your entire notebook, save it, download as HTML and download ipynb. TURN IN both the HTML and the ipynb.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
